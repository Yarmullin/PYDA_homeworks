{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитать про методы оптимизации для нейронных сетей https://habr.com/post/318970/\n",
    "\n",
    "Реализовать самостоятельно логистическую регрессию\n",
    "\n",
    "Обучить ее методом градиентного спуска\n",
    "\n",
    "Методом nesterov momentum\n",
    "\n",
    "Методом rmsprop\n",
    "\n",
    "В качестве dataset’а взять Iris, оставив 2 класса:\n",
    "Iris Versicolor\n",
    "Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySGDClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __sigma(self, t):\n",
    "        t = np.clip(t, -10, 10)\n",
    "        return 1 / (1 + np.exp(-t))\n",
    "    #L1 регуляризация\n",
    "    def __l1_penalty(self):\n",
    "        return 1/self.C * np.sign(self.theta)\n",
    "    #L2 регуляризация\n",
    "    def __l2_penalty(self):\n",
    "        return 1/self.C * self.theta\n",
    "\n",
    "    def __none_penalty(self):\n",
    "        return 0\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.C = kwargs.get('C', 1)\n",
    "        #Коэф. регуляризации\n",
    "        self.alpha = kwargs.get('alpha', 1)               \n",
    "        # Скорость спуска\n",
    "        self.max_epoch = kwargs.get('max_epoch', 10)      \n",
    "        #Максимальное количество эпох при обучении модели\n",
    "        self.chunk_size = kwargs.get('chunk_size', 5)     \n",
    "        #Количество элементов в чанке (от 1 до общего числа точек)\n",
    "        self.min_err = kwargs.get('min_err', 0.1)        \n",
    "        #Пороговое значение ошибки\n",
    "        penalty = kwargs.get('penalty', 'none')           \n",
    "        #Способ расчета регуляризации\n",
    "        \n",
    "        if penalty == 'l1':\n",
    "            self.penalty = self.__l1_penalty \n",
    "        elif penalty == 'l2':\n",
    "            self.penalty = self.__l2_penalty\n",
    "        else:\n",
    "            self.penalty = self.__none_penalty\n",
    "\n",
    "        self.theta = None\n",
    "        self.errors = None\n",
    "        \n",
    "    #Обучение модели\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        import time\n",
    "        np.random.seed(int(time.time()))\n",
    "        eps = 1e-15\n",
    "        n, m = X.shape   \n",
    "        #n - число строк, m - столбцов        \n",
    "        sigma = self.__sigma\n",
    "        chunk_size = self.chunk_size\n",
    "        errors = np.empty(self.max_epoch)\n",
    "        errors[:] = np.nan\n",
    "        X_b = np.c_[X, np.ones(n)]\n",
    "        self.theta = np.random.randn(m + 1, 1)\n",
    "        Y = np.vstack(y)\n",
    "\n",
    "        for epoch in range(self.max_epoch):\n",
    "            lst = list(range(n))\n",
    "            np.random.shuffle(lst)\n",
    "            chunks = [lst[i : i+chunk_size] for i in range(0, n, chunk_size)]\n",
    "            for chunk in chunks:\n",
    "                xi = X_b[chunk]\n",
    "                yi = Y[chunk]\n",
    "                gradients = xi.T.dot(sigma(xi.dot(self.theta)) - yi)\n",
    "                self.theta = self.theta - self.alpha * (gradients + self.penalty())\n",
    "            p = sigma(X_b.dot(self.theta))\n",
    "            p = np.clip(p, eps, 1-eps)\n",
    "            epoch_error = 1 / n * np.sum(-(Y * np.log(p) + (1 - Y)*np.log(1 - p)))\n",
    "            errors[epoch] = epoch_error\n",
    "            if epoch_error <= self.min_err:\n",
    "                break\n",
    "        self.errors = errors\n",
    "        return self\n",
    "\n",
    "   #Возвращение метки класса\n",
    "    def predict(self, X):\n",
    "        y_hat_proba = self.predict_proba(X)\n",
    "        y_hat = np.where(y_hat_proba[0] >= 0.5, 0, 1)\n",
    "        return y_hat\n",
    "\n",
    "   #Возвращение вероятности каждого из классов\n",
    "    def predict_proba(self, X):\n",
    "        if self.theta is None:\n",
    "            raise Exception(\"Model is not fitted yet. Use method 'fit'\")\n",
    "\n",
    "        n, m = X.shape\n",
    "        X_b = np.c_[X, np.ones(n)]\n",
    "        y1 = self.__sigma(X_b.dot(self.theta))\n",
    "        y0 = 1 - y1\n",
    "        y_hat_proba = np.c_[y0, y1]\n",
    "        return y_hat_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNesterovClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __sigma(self, t):\n",
    "        t = np.clip(t, -10, 10)\n",
    "        return 1 / (1 + np.exp(-t))\n",
    "    #L1 регуляризация\n",
    "    def __l1_penalty(self):\n",
    "        return 1/self.C * np.sign(self.theta)\n",
    "    #L2 регуляризация\n",
    "    def __l2_penalty(self):\n",
    "        return 1/self.C * self.theta\n",
    "\n",
    "    def __none_penalty(self):\n",
    "        return 0\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.C = kwargs.get('C', 1)\n",
    "        #Коэф. регуляризации\n",
    "        self.alpha = kwargs.get('alpha', 1)               \n",
    "        # Скорость спуска\n",
    "        self.max_epoch = kwargs.get('max_epoch', 10)      \n",
    "        #Максимальное количество эпох при обучении модели\n",
    "        self.chunk_size = kwargs.get('chunk_size', 5)     \n",
    "        #Количество элементов в чанке (от 1 до общего числа точек)\n",
    "        self.min_err = kwargs.get('min_err', 0.1)        \n",
    "        #Пороговое значение ошибки\n",
    "        self.gamma = kwargs.get('gamma', 0.9)\n",
    "        #К-т релаксации\n",
    "        penalty = kwargs.get('penalty', 'none')           \n",
    "        #Способ расчета регуляризации\n",
    "        \n",
    "        if penalty == 'l1':\n",
    "            self.penalty = self.__l1_penalty \n",
    "        elif penalty == 'l2':\n",
    "            self.penalty = self.__l2_penalty\n",
    "        else:\n",
    "            self.penalty = self.__none_penalty\n",
    "\n",
    "        self.theta = None\n",
    "        self.errors = None\n",
    "        \n",
    "    #Обучение модели\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        import time\n",
    "        np.random.seed(int(time.time()))\n",
    "        eps = 1e-15\n",
    "        n, m = X.shape   \n",
    "        #n - число строк, m - столбцов        \n",
    "        sigma = self.__sigma\n",
    "        chunk_size = self.chunk_size\n",
    "        errors = np.empty(self.max_epoch)\n",
    "        errors[:] = np.nan\n",
    "        X_b = np.c_[X, np.ones(n)]\n",
    "        self.theta = np.random.randn(m + 1, 1)\n",
    "        Y = np.vstack(y)\n",
    "\n",
    "        for epoch in range(self.max_epoch):\n",
    "            lst = list(range(n))\n",
    "            np.random.shuffle(lst)\n",
    "            chunks = [lst[i : i+chunk_size] for i in range(0, n, chunk_size)]\n",
    "            grad_accum = 0\n",
    "            for chunk in chunks:\n",
    "                xi = X_b[chunk]\n",
    "                yi = Y[chunk]\n",
    "                gradients = xi.T.dot(sigma(xi.dot(self.theta)) - yi)\n",
    "                grad_accum = self.gamma * grad_accum + (1- self.gamma) * gradients\n",
    "                self.theta = self.theta - self.alpha * (grad_accum + self.penalty())\n",
    "            p = sigma(X_b.dot(self.theta))\n",
    "            p = np.clip(p, eps, 1-eps)\n",
    "            epoch_error = 1 / n * np.sum(-(Y * np.log(p) + (1 - Y)*np.log(1 - p)))\n",
    "            errors[epoch] = epoch_error\n",
    "            if epoch_error <= self.min_err:\n",
    "                break\n",
    "        self.errors = errors\n",
    "        return self\n",
    "\n",
    "   #Возвращение метки класса\n",
    "    def predict(self, X):\n",
    "        y_hat_proba = self.predict_proba(X)\n",
    "        y_hat = np.where(y_hat_proba[0] >= 0.5, 0, 1)\n",
    "        return y_hat\n",
    "\n",
    "   #Возвращение вероятности каждого из классов\n",
    "    def predict_proba(self, X):\n",
    "        if self.theta is None:\n",
    "            raise Exception(\"Model is not fitted yet. Use method 'fit'\")\n",
    "\n",
    "        n, m = X.shape\n",
    "        X_b = np.c_[X, np.ones(n)]\n",
    "        y1 = self.__sigma(X_b.dot(self.theta))\n",
    "        y0 = 1 - y1\n",
    "        y_hat_proba = np.c_[y0, y1]\n",
    "        return y_hat_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRMSClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __sigma(self, t):\n",
    "        t = np.clip(t, -10, 10)\n",
    "        return 1 / (1 + np.exp(-t))\n",
    "    #L1 регуляризация\n",
    "    def __l1_penalty(self):\n",
    "        return 1/self.C * np.sign(self.theta)\n",
    "    #L2 регуляризация\n",
    "    def __l2_penalty(self):\n",
    "        return 1/self.C * self.theta\n",
    "\n",
    "    def __none_penalty(self):\n",
    "        return 0\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.C = kwargs.get('C', 1)\n",
    "        #Коэф. регуляризации\n",
    "        self.alpha = kwargs.get('alpha', 1)               \n",
    "        # Скорость спуска\n",
    "        self.max_epoch = kwargs.get('max_epoch', 10)      \n",
    "        #Максимальное количество эпох при обучении модели\n",
    "        self.chunk_size = kwargs.get('chunk_size', 5)     \n",
    "        #Количество элементов в чанке (от 1 до общего числа точек)\n",
    "        self.min_err = kwargs.get('min_err', 0.1)        \n",
    "        #Пороговое значение ошибки\n",
    "        self.gamma = kwargs.get('gamma', 0.9)\n",
    "        #К-т релаксации\n",
    "        penalty = kwargs.get('penalty', 'none')           \n",
    "        #Способ расчета регуляризации\n",
    "        \n",
    "        if penalty == 'l1':\n",
    "            self.penalty = self.__l1_penalty \n",
    "        elif penalty == 'l2':\n",
    "            self.penalty = self.__l2_penalty\n",
    "        else:\n",
    "            self.penalty = self.__none_penalty\n",
    "\n",
    "        self.theta = None\n",
    "        self.errors = None\n",
    "        \n",
    "    #Обучение модели\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        import time\n",
    "        np.random.seed(int(time.time()))\n",
    "        eps = 1e-15\n",
    "        n, m = X.shape   \n",
    "        #n - число строк, m - столбцов        \n",
    "        sigma = self.__sigma\n",
    "        chunk_size = self.chunk_size\n",
    "        errors = np.empty(self.max_epoch)\n",
    "        errors[:] = np.nan\n",
    "        X_b = np.c_[X, np.ones(n)]\n",
    "        self.theta = np.random.randn(m + 1, 1)\n",
    "        Y = np.vstack(y)\n",
    "\n",
    "        for epoch in range(self.max_epoch):\n",
    "            lst = list(range(n))\n",
    "            np.random.shuffle(lst)\n",
    "            chunks = [lst[i : i+chunk_size] for i in range(0, n, chunk_size)]\n",
    "            grad_accum = 0\n",
    "            for chunk in chunks:\n",
    "                xi = X_b[chunk]\n",
    "                yi = Y[chunk]\n",
    "                gradients = xi.T.dot(sigma(xi.dot(self.theta)) - yi)\n",
    "                grad_accum = self.gamma * (grad_accum) + (1- self.gamma) * (gradients**2)\n",
    "                self.theta = self.theta - (self.alpha / (sqrt(grad_accum+eps)))*(gradients + self.penalty())\n",
    "            p = sigma(X_b.dot(self.theta))\n",
    "            p = np.clip(p, eps, 1-eps)\n",
    "            epoch_error = 1 / n * np.sum(-(Y * np.log(p) + (1 - Y)*np.log(1 - p)))\n",
    "            errors[epoch] = epoch_error\n",
    "            if epoch_error <= self.min_err:\n",
    "                break\n",
    "        self.errors = errors\n",
    "        return self\n",
    "\n",
    "   #Возвращение метки класса\n",
    "    def predict(self, X):\n",
    "        y_hat_proba = self.predict_proba(X)\n",
    "        y_hat = np.where(y_hat_proba[0] >= 0.5, 0, 1)\n",
    "        return y_hat\n",
    "\n",
    "   #Возвращение вероятности каждого из классов\n",
    "    def predict_proba(self, X):\n",
    "        if self.theta is None:\n",
    "            raise Exception(\"Model is not fitted yet. Use method 'fit'\")\n",
    "\n",
    "        n, m = X.shape\n",
    "        X_b = np.c_[X, np.ones(n)]\n",
    "        y1 = self.__sigma(X_b.dot(self.theta))\n",
    "        y0 = 1 - y1\n",
    "        y_hat_proba = np.c_[y0, y1]\n",
    "        return y_hat_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Датасет с ирисами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "data['variety'] = iris.target\n",
    "data = data[data['variety'] != 0]\n",
    "y = data['variety']\n",
    "del data['variety']\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta =  [[ 4.12999721]\n",
      " [ 3.46785146]\n",
      " [ 2.65272   ]\n",
      " [-1.00446279]\n",
      " [ 1.12968293]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_epoch = 20\n",
    "SGD = MySGDClassifier(alpha=.01, max_epoch=max_epoch, penalty = 'none', C = 100)\n",
    "SGD.fit(X, y)\n",
    "print(\"theta = \", SGD.theta)\n",
    "SGD.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta =  [[ 2.33287049]\n",
      " [ 1.08537504]\n",
      " [ 3.38641971]\n",
      " [-0.31755976]\n",
      " [ 1.08600686]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAG = MyNesterovClassifier(alpha=.01, max_epoch=max_epoch, penalty = 'none', C = 100)\n",
    "NAG.fit(X, y)\n",
    "print(\"theta = \", NAG.theta)\n",
    "NAG.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta =  [[ 1.68228578]\n",
      " [-0.20199797]\n",
      " [ 4.0894357 ]\n",
      " [-0.10408952]\n",
      " [ 1.35707627]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01],\n",
       "       [4.53978687e-05, 9.99954602e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMS = MyNesterovClassifier(alpha=.01, max_epoch=max_epoch, penalty = 'none', C = 100)\n",
    "RMS.fit(X, y)\n",
    "print(\"theta = \", RMS.theta)\n",
    "RMS.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
